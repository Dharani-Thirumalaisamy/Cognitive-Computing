{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part2A_BaselineModel.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ZB8OmG8fn0Km","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"07a2289c-e168-4cd2-a0b9-ad337965df6a","executionInfo":{"status":"ok","timestamp":1539219309264,"user_tz":240,"elapsed":2708,"user":{"displayName":"Pramod Nagare","photoUrl":"","userId":"02946701304053827526"}}},"cell_type":"code","source":["from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import os"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"muNVcE5rn_EP","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 100\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jT9tMQdQoLu8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"27196f7f-2d8e-4cab-d021-00e2e61d0895","executionInfo":{"status":"ok","timestamp":1539219442408,"user_tz":240,"elapsed":132503,"user":{"displayName":"Pramod Nagare","photoUrl":"","userId":"02946701304053827526"}}},"cell_type":"code","source":["# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 129s 1us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"metadata":{"id":"4bTc7PQGoOn0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nYCTmCWuoq0i","colab_type":"code","colab":{}},"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CvxhIh7mo2Ad","colab_type":"code","colab":{}},"cell_type":"code","source":["# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iutVZjZuo3vl","colab_type":"code","colab":{}},"cell_type":"code","source":["# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5D58CG5ko6M7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3471},"outputId":"2d5cae90-f301-425c-8178-b56105ce9e65","executionInfo":{"status":"ok","timestamp":1539224179544,"user_tz":240,"elapsed":4734332,"user":{"displayName":"Pramod Nagare","photoUrl":"","userId":"02946701304053827526"}}},"cell_type":"code","source":["if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    history = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using real-time data augmentation.\n","WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n","Epoch 1/100\n","1563/1563 [==============================] - 51s 33ms/step - loss: 1.8746 - acc: 0.3062 - val_loss: 1.5780 - val_acc: 0.4239\n","Epoch 2/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.6000 - acc: 0.4155 - val_loss: 1.3904 - val_acc: 0.4897\n","Epoch 3/100\n","1563/1563 [==============================] - 48s 31ms/step - loss: 1.4754 - acc: 0.4640 - val_loss: 1.3263 - val_acc: 0.5280\n","Epoch 4/100\n","1563/1563 [==============================] - 48s 31ms/step - loss: 1.3957 - acc: 0.4981 - val_loss: 1.2367 - val_acc: 0.5569\n","Epoch 5/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.3279 - acc: 0.5237 - val_loss: 1.1574 - val_acc: 0.5841\n","Epoch 6/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.2729 - acc: 0.5461 - val_loss: 1.1359 - val_acc: 0.5969\n","Epoch 7/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.2198 - acc: 0.5656 - val_loss: 1.1701 - val_acc: 0.5903\n","Epoch 8/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.1763 - acc: 0.5833 - val_loss: 1.0304 - val_acc: 0.6321\n","Epoch 9/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.1370 - acc: 0.5967 - val_loss: 1.0070 - val_acc: 0.6473\n","Epoch 10/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.0982 - acc: 0.6102 - val_loss: 0.9458 - val_acc: 0.6687\n","Epoch 11/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.0658 - acc: 0.6211 - val_loss: 0.9399 - val_acc: 0.6720\n","Epoch 12/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.0406 - acc: 0.6316 - val_loss: 0.9714 - val_acc: 0.6697\n","Epoch 13/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 1.0217 - acc: 0.6403 - val_loss: 0.9614 - val_acc: 0.6639\n","Epoch 14/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.9942 - acc: 0.6516 - val_loss: 0.8774 - val_acc: 0.6928\n","Epoch 15/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.9750 - acc: 0.6607 - val_loss: 0.8841 - val_acc: 0.6939\n","Epoch 16/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.9508 - acc: 0.6668 - val_loss: 0.8535 - val_acc: 0.7008\n","Epoch 17/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.9384 - acc: 0.6725 - val_loss: 0.8264 - val_acc: 0.7100\n","Epoch 18/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.9207 - acc: 0.6785 - val_loss: 0.8292 - val_acc: 0.7087\n","Epoch 19/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.9136 - acc: 0.6816 - val_loss: 0.8804 - val_acc: 0.6985\n","Epoch 20/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8973 - acc: 0.6859 - val_loss: 0.7982 - val_acc: 0.7184\n","Epoch 21/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8859 - acc: 0.6901 - val_loss: 0.7945 - val_acc: 0.7205\n","Epoch 22/100\n","1563/1563 [==============================] - 48s 31ms/step - loss: 0.8836 - acc: 0.6922 - val_loss: 0.8112 - val_acc: 0.7266\n","Epoch 23/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8753 - acc: 0.6962 - val_loss: 0.8011 - val_acc: 0.7226\n","Epoch 24/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8676 - acc: 0.7018 - val_loss: 0.7501 - val_acc: 0.7385\n","Epoch 25/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8565 - acc: 0.7045 - val_loss: 0.8290 - val_acc: 0.7187\n","Epoch 26/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8500 - acc: 0.7067 - val_loss: 0.7844 - val_acc: 0.7287\n","Epoch 27/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8466 - acc: 0.7099 - val_loss: 0.7828 - val_acc: 0.7272\n","Epoch 28/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8422 - acc: 0.7091 - val_loss: 0.7833 - val_acc: 0.7342\n","Epoch 29/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8379 - acc: 0.7131 - val_loss: 0.7427 - val_acc: 0.7431\n","Epoch 30/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8319 - acc: 0.7162 - val_loss: 0.7664 - val_acc: 0.7347\n","Epoch 31/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8314 - acc: 0.7131 - val_loss: 0.7239 - val_acc: 0.7511\n","Epoch 32/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8231 - acc: 0.7188 - val_loss: 0.7688 - val_acc: 0.7372\n","Epoch 33/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8227 - acc: 0.7177 - val_loss: 0.8235 - val_acc: 0.7303\n","Epoch 34/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8232 - acc: 0.7193 - val_loss: 0.7245 - val_acc: 0.7555\n","Epoch 35/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8197 - acc: 0.7191 - val_loss: 0.7406 - val_acc: 0.7495\n","Epoch 36/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8184 - acc: 0.7195 - val_loss: 0.7155 - val_acc: 0.7599\n","Epoch 37/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8121 - acc: 0.7216 - val_loss: 0.7188 - val_acc: 0.7567\n","Epoch 38/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8129 - acc: 0.7235 - val_loss: 0.7126 - val_acc: 0.7562\n","Epoch 39/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8069 - acc: 0.7234 - val_loss: 0.7425 - val_acc: 0.7498\n","Epoch 40/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8102 - acc: 0.7256 - val_loss: 0.7384 - val_acc: 0.7505\n","Epoch 41/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.8035 - acc: 0.7245 - val_loss: 0.7521 - val_acc: 0.7503\n","Epoch 42/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8006 - acc: 0.7285 - val_loss: 0.7931 - val_acc: 0.7292\n","Epoch 43/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7969 - acc: 0.7274 - val_loss: 0.7524 - val_acc: 0.7468\n","Epoch 44/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8014 - acc: 0.7272 - val_loss: 0.7298 - val_acc: 0.7557\n","Epoch 45/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8000 - acc: 0.7301 - val_loss: 0.6978 - val_acc: 0.7692\n","Epoch 46/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7943 - acc: 0.7311 - val_loss: 0.8018 - val_acc: 0.7254\n","Epoch 47/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7960 - acc: 0.7295 - val_loss: 0.7559 - val_acc: 0.7465\n","Epoch 48/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7952 - acc: 0.7303 - val_loss: 0.7356 - val_acc: 0.7520\n","Epoch 49/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7907 - acc: 0.7342 - val_loss: 0.6928 - val_acc: 0.7711\n","Epoch 50/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7916 - acc: 0.7310 - val_loss: 0.7285 - val_acc: 0.7568\n","Epoch 51/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7900 - acc: 0.7323 - val_loss: 0.7207 - val_acc: 0.7599\n","Epoch 52/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7833 - acc: 0.7358 - val_loss: 0.7266 - val_acc: 0.7573\n","Epoch 53/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7895 - acc: 0.7320 - val_loss: 0.7377 - val_acc: 0.7502\n","Epoch 54/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7881 - acc: 0.7332 - val_loss: 0.7166 - val_acc: 0.7617\n","Epoch 55/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7889 - acc: 0.7350 - val_loss: 0.7468 - val_acc: 0.7515\n","Epoch 56/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7861 - acc: 0.7357 - val_loss: 0.6941 - val_acc: 0.7635\n","Epoch 57/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7861 - acc: 0.7359 - val_loss: 0.7189 - val_acc: 0.7564\n","Epoch 58/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7822 - acc: 0.7379 - val_loss: 0.7272 - val_acc: 0.7566\n","Epoch 59/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7878 - acc: 0.7370 - val_loss: 0.7223 - val_acc: 0.7577\n","Epoch 60/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7856 - acc: 0.7361 - val_loss: 0.7390 - val_acc: 0.7528\n","Epoch 61/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7830 - acc: 0.7368 - val_loss: 0.7057 - val_acc: 0.7652\n","Epoch 62/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7837 - acc: 0.7366 - val_loss: 0.6764 - val_acc: 0.7755\n","Epoch 63/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7794 - acc: 0.7386 - val_loss: 0.7687 - val_acc: 0.7483\n","Epoch 64/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7847 - acc: 0.7344 - val_loss: 0.7292 - val_acc: 0.7642\n","Epoch 65/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7820 - acc: 0.7368 - val_loss: 0.7531 - val_acc: 0.7671\n","Epoch 66/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7847 - acc: 0.7385 - val_loss: 0.7179 - val_acc: 0.7716\n","Epoch 67/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7875 - acc: 0.7358 - val_loss: 0.6585 - val_acc: 0.7809\n","Epoch 68/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7833 - acc: 0.7391 - val_loss: 0.6880 - val_acc: 0.7817\n","Epoch 69/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7816 - acc: 0.7351 - val_loss: 0.6876 - val_acc: 0.7779\n","Epoch 70/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7806 - acc: 0.7400 - val_loss: 0.6743 - val_acc: 0.7876\n","Epoch 71/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7886 - acc: 0.7368 - val_loss: 0.7263 - val_acc: 0.7560\n","Epoch 72/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7881 - acc: 0.7371 - val_loss: 0.7021 - val_acc: 0.7710\n","Epoch 73/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7838 - acc: 0.7380 - val_loss: 0.7437 - val_acc: 0.7496\n","Epoch 74/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7820 - acc: 0.7382 - val_loss: 0.7157 - val_acc: 0.7665\n","Epoch 75/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7816 - acc: 0.7379 - val_loss: 0.7226 - val_acc: 0.7612\n","Epoch 76/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7810 - acc: 0.7391 - val_loss: 0.7665 - val_acc: 0.7435\n","Epoch 77/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7857 - acc: 0.7371 - val_loss: 0.7229 - val_acc: 0.7579\n","Epoch 78/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7842 - acc: 0.7363 - val_loss: 0.6522 - val_acc: 0.7824\n","Epoch 79/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7847 - acc: 0.7401 - val_loss: 0.7751 - val_acc: 0.7487\n","Epoch 80/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7921 - acc: 0.7383 - val_loss: 0.7390 - val_acc: 0.7612\n","Epoch 81/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7952 - acc: 0.7345 - val_loss: 0.7587 - val_acc: 0.7614\n","Epoch 82/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7887 - acc: 0.7381 - val_loss: 0.7421 - val_acc: 0.7531\n","Epoch 83/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7900 - acc: 0.7354 - val_loss: 0.7264 - val_acc: 0.7565\n","Epoch 84/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7893 - acc: 0.7383 - val_loss: 0.7212 - val_acc: 0.7600\n","Epoch 85/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7929 - acc: 0.7356 - val_loss: 0.7908 - val_acc: 0.7540\n","Epoch 86/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7955 - acc: 0.7357 - val_loss: 0.7564 - val_acc: 0.7454\n","Epoch 87/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7958 - acc: 0.7348 - val_loss: 0.6460 - val_acc: 0.7853\n","Epoch 88/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7960 - acc: 0.7352 - val_loss: 0.7691 - val_acc: 0.7425\n","Epoch 89/100\n","1563/1563 [==============================] - 48s 30ms/step - loss: 0.7934 - acc: 0.7375 - val_loss: 0.6859 - val_acc: 0.7767\n","Epoch 90/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7972 - acc: 0.7372 - val_loss: 0.7948 - val_acc: 0.7376\n","Epoch 91/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7962 - acc: 0.7356 - val_loss: 0.6795 - val_acc: 0.7707\n","Epoch 92/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7999 - acc: 0.7343 - val_loss: 0.8231 - val_acc: 0.7270\n","Epoch 93/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.7994 - acc: 0.7360 - val_loss: 0.7128 - val_acc: 0.7654\n","Epoch 94/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8025 - acc: 0.7355 - val_loss: 0.7510 - val_acc: 0.7449\n","Epoch 95/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8053 - acc: 0.7329 - val_loss: 0.8109 - val_acc: 0.7359\n","Epoch 96/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8066 - acc: 0.7330 - val_loss: 0.7671 - val_acc: 0.7416\n","Epoch 97/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8062 - acc: 0.7331 - val_loss: 0.8183 - val_acc: 0.7229\n","Epoch 98/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8060 - acc: 0.7322 - val_loss: 0.7916 - val_acc: 0.7600\n","Epoch 99/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8141 - acc: 0.7316 - val_loss: 0.7146 - val_acc: 0.7664\n","Epoch 100/100\n","1563/1563 [==============================] - 47s 30ms/step - loss: 0.8071 - acc: 0.7314 - val_loss: 0.6666 - val_acc: 0.7769\n"],"name":"stdout"}]},{"metadata":{"id":"zKqCodTfo8gP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"fEV8E_zb8EX_","colab_type":"text"},"cell_type":"markdown","source":["#Comments:\n","\n","Training Accuracy: 72-73%\n","\n","Training Loss: 79-81%\n","\n","Testing Accuracy: 75-77%\n","\n","Testing Loss: 69-72%"]},{"metadata":{"id":"DUoVQeHM8E9x","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lcz-V6lM8Vb0","colab_type":"text"},"cell_type":"markdown","source":["# Conclusion:\n","\n","The model Test & Train accuracy starts increasing from very first epoch gradually.\n","\n","However it reaches max accuracy ariund 73% on the 45th epoch. Onwards its almost constant.\n","\n","Also, In  most of the cases we got testing accuracy more than the "]}]}